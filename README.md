
# Local LLM Demonstration with Hugging Face Models

## Introduction
This project demonstrates the capabilities of three LLMs from Hugging Face run on a local machine. It focuses on comparing the responses from different models when presented with identical questions, offering insights into their capabilities and use cases.


## Models Used
- **flan-t5-small**: A smaller, efficient version of the T5 model designed for few-shot learning, suitable for a variety of NLP tasks.
- **dolly-v2-3b**: A model focused on generating coherent and contextually appropriate text in a generative manner.
- **DialoGPT-large**: A model specialized in dialogue, optimizing for conversational contexts and maintaining coherence over multiple turns of conversation.


## Setup and Installation
To run this notebook, you will need to install a few Python packages, primarily those from the Hugging Face `transformers` library. Ensure your local environment is set up with the packages listed in the `requirements.txt` file.


## How to Run the Notebook
1. Clone the repository containing the notebook.
2. Install the required dependencies as listed in the Setup and Installation section.
3. Open the notebook in Jupyter Lab or Jupyter Notebook.
4. Run each cell sequentially to see the models in action.


## Examples of Usage
The notebook includes cells that demonstrate the use of each model. To see the models' responses to specific queries, simply input queries as demonstrated in the notebook and observe the output.


## License
This project is licensed under the MIT License - see the LICENSE file for details.
